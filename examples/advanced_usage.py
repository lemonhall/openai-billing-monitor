"""
é«˜çº§ä½¿ç”¨ç¤ºä¾‹ - OpenAI Billing Monitor
"""

import os
import time
import asyncio
from typing import List, Dict, Any
import openai
from openai_billing import BillingMonitor, OpenAIWrapper, monitor_openai_call
from openai_billing.models import ModelConfig, ThresholdConfig
from openai_billing.core.exceptions import ThresholdExceededException


class ChatBot:
    """ç¤ºä¾‹èŠå¤©æœºå™¨äººç±»ï¼Œé›†æˆè®¡è´¹ç›‘æ§"""
    
    def __init__(self, model_name: str = "gpt-3.5-turbo"):
        self.model_name = model_name
        self.client = OpenAIWrapper()
        self.conversation_history = []
        
        # è®¾ç½®å›è°ƒå‡½æ•°
        self.setup_callbacks()
    
    def setup_callbacks(self):
        """è®¾ç½®ç›‘æ§å›è°ƒ"""
        def on_warning(warning_type, usage_info):
            print(f"ğŸ’° æˆæœ¬è­¦å‘Š: {warning_type}")
            print(f"   å½“å‰æ—¥æˆæœ¬: ${usage_info['daily_cost']:.4f}")
        
        def on_exceeded(exceeded_type, usage_info):
            print(f"ğŸš« è¶…å‡ºé™åˆ¶: {exceeded_type}")
            print(f"   åœæ­¢æœåŠ¡ä»¥æ§åˆ¶æˆæœ¬")
        
        self.client.set_threshold_callbacks(
            on_warning=on_warning,
            on_exceeded=on_exceeded
        )
    
    def chat(self, message: str) -> str:
        """èŠå¤©æ–¹æ³•ï¼Œè‡ªåŠ¨ç›‘æ§æˆæœ¬"""
        self.conversation_history.append({"role": "user", "content": message})
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=self.conversation_history,
                max_tokens=150
            )
            
            assistant_message = response.choices[0].message.content
            self.conversation_history.append({"role": "assistant", "content": assistant_message})
            
            return assistant_message
            
        except ThresholdExceededException as e:
            return f"æŠ±æ­‰ï¼Œå·²è¾¾åˆ°ä½¿ç”¨é™åˆ¶: {e}"
        except Exception as e:
            return f"å‘ç”Ÿé”™è¯¯: {e}"
    
    def get_usage_stats(self) -> Dict[str, Any]:
        """è·å–ä½¿ç”¨ç»Ÿè®¡"""
        return self.client.get_usage_summary()


class BatchProcessor:
    """æ‰¹é‡å¤„ç†ç¤ºä¾‹ï¼Œå¸¦æœ‰æˆæœ¬æ§åˆ¶"""
    
    def __init__(self):
        self.monitor = BillingMonitor()
        self.client = openai.OpenAI()
    
    @monitor_openai_call()
    def process_single_item(self, text: str, model: str = "gpt-3.5-turbo") -> str:
        """å¤„ç†å•ä¸ªé¡¹ç›®"""
        response = self.client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are a helpful assistant that summarizes text."},
                {"role": "user", "content": f"Summarize this text: {text}"}
            ],
            max_tokens=100
        )
        return response.choices[0].message.content
    
    def process_batch(self, texts: List[str], model: str = "gpt-3.5-turbo") -> List[str]:
        """æ‰¹é‡å¤„ç†ï¼Œå¸¦æœ‰æˆæœ¬æ§åˆ¶"""
        results = []
        total_estimated_cost = 0
        
        for i, text in enumerate(texts):
            # é¢„ä¼°æˆæœ¬
            estimated_tokens = len(text.split()) * 1.3  # ç²—ç•¥ä¼°ç®—
            check_result = self.monitor.check_limits_before_request(model, int(estimated_tokens))
            
            if not check_result["allowed"]:
                print(f"âš ï¸ ç¬¬{i+1}ä¸ªé¡¹ç›®è¢«è·³è¿‡ï¼ŒåŸå› : è¶…å‡ºé™åˆ¶")
                warnings = check_result.get("warnings", [])
                for warning in warnings:
                    print(f"   {warning['message']}")
                continue
            
            try:
                result = self.process_single_item(text, model)
                results.append(result)
                total_estimated_cost += check_result["estimated_cost"]
                
                print(f"âœ… å¤„ç†å®Œæˆç¬¬{i+1}/{len(texts)}ä¸ªé¡¹ç›®")
                print(f"   é¢„ä¼°ç´¯è®¡æˆæœ¬: ${total_estimated_cost:.4f}")
                
                # æ·»åŠ å»¶è¿Ÿé¿å…é€Ÿç‡é™åˆ¶
                time.sleep(1)
                
            except ThresholdExceededException as e:
                print(f"ğŸš« å¤„ç†ç¬¬{i+1}ä¸ªé¡¹ç›®æ—¶è¶…å‡ºé™åˆ¶: {e}")
                break
            except Exception as e:
                print(f"âŒ å¤„ç†ç¬¬{i+1}ä¸ªé¡¹ç›®æ—¶å‡ºé”™: {e}")
                continue
        
        return results


class ModelComparison:
    """æ¨¡å‹æˆæœ¬æ¯”è¾ƒå·¥å…·"""
    
    def __init__(self):
        self.monitor = BillingMonitor()
    
    def compare_models(self, prompt: str, models: List[str]) -> Dict[str, Dict[str, Any]]:
        """æ¯”è¾ƒä¸åŒæ¨¡å‹çš„æˆæœ¬å’Œå“åº”"""
        results = {}
        
        for model in models:
            print(f"\nğŸ” æµ‹è¯•æ¨¡å‹: {model}")
            
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦é…ç½®
            model_config = self.monitor.config.get_model_config(model)
            if not model_config:
                print(f"âš ï¸ æ¨¡å‹ {model} æœªé…ç½®ï¼Œè·³è¿‡")
                continue
            
            # ä¼°ç®—æˆæœ¬
            estimated_tokens = len(prompt.split()) * 1.5
            estimated_cost = self.monitor.estimate_cost(model, int(estimated_tokens), int(estimated_tokens))
            
            results[model] = {
                "estimated_cost": estimated_cost,
                "input_price": model_config.input_token_price,
                "output_price": model_config.output_token_price,
                "max_tokens": model_config.max_tokens
            }
            
            print(f"   é¢„ä¼°æˆæœ¬: ${estimated_cost:.6f}")
            print(f"   è¾“å…¥ä»·æ ¼: ${model_config.input_token_price:.6f}/1K tokens")
            print(f"   è¾“å‡ºä»·æ ¼: ${model_config.output_token_price:.6f}/1K tokens")
        
        # æ’åºå¹¶æ˜¾ç¤ºæœ€ç»æµçš„é€‰æ‹©
        if results:
            sorted_models = sorted(results.items(), key=lambda x: x[1]["estimated_cost"])
            print(f"\nğŸ’° æœ€ç»æµçš„æ¨¡å‹: {sorted_models[0][0]} (${sorted_models[0][1]['estimated_cost']:.6f})")
        
        return results


class CostTracker:
    """æˆæœ¬è·Ÿè¸ªå’ŒæŠ¥å‘Šå·¥å…·"""
    
    def __init__(self):
        self.monitor = BillingMonitor()
    
    def generate_report(self) -> str:
        """ç”Ÿæˆä½¿ç”¨æŠ¥å‘Š"""
        summary = self.monitor.get_usage_summary()
        
        report = f"""
ğŸ“Š OpenAI ä½¿ç”¨æŠ¥å‘Š
{'=' * 50}

ğŸ’° æˆæœ¬ç»Ÿè®¡:
   æ€»æˆæœ¬:     ${summary.get('total_cost', 0):.4f}
   ä»Šæ—¥æˆæœ¬:   ${summary.get('daily_cost', 0):.4f}
   æœ¬æœˆæˆæœ¬:   ${summary.get('monthly_cost', 0):.4f}

ğŸ”¢ Tokenç»Ÿè®¡:
   æ€»è¾“å…¥:     {summary.get('total_input_tokens', 0):,}
   æ€»è¾“å‡º:     {summary.get('total_output_tokens', 0):,}
   ä»Šæ—¥è¾“å…¥:   {summary.get('daily_input_tokens', 0):,}
   ä»Šæ—¥è¾“å‡º:   {summary.get('daily_output_tokens', 0):,}

ğŸ“ è¯·æ±‚ç»Ÿè®¡:
   æ€»è¯·æ±‚æ•°:   {summary.get('total_requests', 0):,}

ğŸ“… æ—¶é—´ä¿¡æ¯:
   ä¸Šæ¬¡é‡ç½®:   {summary.get('last_reset_date', 'N/A')}
   æ—¥é‡ç½®:     {summary.get('last_daily_reset', 'N/A')}
   æœˆé‡ç½®:     {summary.get('last_monthly_reset', 'N/A')}

âš ï¸ é™åˆ¶çŠ¶æ€:
"""
        
        # æ·»åŠ é™åˆ¶çŠ¶æ€
        if summary.get('daily_cost_limit'):
            daily_percent = summary.get('daily_cost_usage_percent', 0)
            status = "ğŸ”´" if daily_percent >= 100 else "ğŸŸ¡" if daily_percent >= 80 else "ğŸŸ¢"
            report += f"   æ—¥æˆæœ¬é™åˆ¶: {status} {daily_percent:.1f}% (${summary['daily_cost_limit']:.2f})\n"
        
        if summary.get('monthly_cost_limit'):
            monthly_percent = summary.get('monthly_cost_usage_percent', 0)
            status = "ğŸ”´" if monthly_percent >= 100 else "ğŸŸ¡" if monthly_percent >= 80 else "ğŸŸ¢"
            report += f"   æœˆæˆæœ¬é™åˆ¶: {status} {monthly_percent:.1f}% (${summary['monthly_cost_limit']:.2f})\n"
        
        return report
    
    def export_data(self, filename: str):
        """å¯¼å‡ºæ•°æ®åˆ°æ–‡ä»¶"""
        import json
        
        summary = self.monitor.get_usage_summary()
        config_data = {
            "export_time": time.strftime("%Y-%m-%d %H:%M:%S"),
            "usage_summary": summary,
            "models_configured": list(self.monitor.config.models.keys()),
            "thresholds": {
                "daily_cost_limit": self.monitor.config.thresholds.daily_cost_limit,
                "monthly_cost_limit": self.monitor.config.thresholds.monthly_cost_limit,
                "daily_token_limit": self.monitor.config.thresholds.daily_token_limit,
                "monthly_token_limit": self.monitor.config.thresholds.monthly_token_limit,
                "warning_threshold": self.monitor.config.thresholds.warning_threshold,
            }
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(config_data, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"ğŸ“ æ•°æ®å·²å¯¼å‡ºåˆ°: {filename}")


def example_chatbot():
    """ç¤ºä¾‹: èŠå¤©æœºå™¨äºº"""
    print("\n=== èŠå¤©æœºå™¨äººç¤ºä¾‹ ===")
    
    try:
        bot = ChatBot("gpt-3.5-turbo")
        
        # æ¨¡æ‹Ÿå¯¹è¯
        messages = [
            "Hello, how are you?",
            "What's the weather like?", 
            "Tell me a joke"
        ]
        
        for msg in messages:
            print(f"User: {msg}")
            response = bot.chat(msg)
            print(f"Bot: {response}")
            
            # æ˜¾ç¤ºå½“å‰ä½¿ç”¨ç»Ÿè®¡
            stats = bot.get_usage_stats()
            print(f"ğŸ’° å½“å‰æˆæœ¬: ${stats['daily_cost']:.4f}")
            print("-" * 40)
        
    except Exception as e:
        print(f"Error: {e}")


def example_batch_processing():
    """ç¤ºä¾‹: æ‰¹é‡å¤„ç†"""
    print("\n=== æ‰¹é‡å¤„ç†ç¤ºä¾‹ ===")
    
    try:
        processor = BatchProcessor()
        
        # ç¤ºä¾‹æ–‡æœ¬åˆ—è¡¨
        texts = [
            "This is a long article about artificial intelligence and machine learning...",
            "Another piece of text that needs to be summarized for our project...",
            "The third document contains important information about data processing..."
        ]
        
        # æ‰¹é‡å¤„ç†
        results = processor.process_batch(texts)
        
        print(f"\nâœ… å¤„ç†å®Œæˆï¼Œå…±{len(results)}ä¸ªç»“æœ")
        for i, result in enumerate(results):
            print(f"{i+1}. {result}")
        
    except Exception as e:
        print(f"Error: {e}")


def example_model_comparison():
    """ç¤ºä¾‹: æ¨¡å‹æ¯”è¾ƒ"""
    print("\n=== æ¨¡å‹æ¯”è¾ƒç¤ºä¾‹ ===")
    
    try:
        comparator = ModelComparison()
        
        prompt = "Explain the concept of machine learning in simple terms"
        models = ["gpt-3.5-turbo", "gpt-4", "gpt-4o-mini"]
        
        results = comparator.compare_models(prompt, models)
        
        print("\nğŸ“Š æ¯”è¾ƒç»“æœ:")
        for model, data in results.items():
            print(f"{model}: ${data['estimated_cost']:.6f}")
        
    except Exception as e:
        print(f"Error: {e}")


def example_cost_tracking():
    """ç¤ºä¾‹: æˆæœ¬è·Ÿè¸ª"""
    print("\n=== æˆæœ¬è·Ÿè¸ªç¤ºä¾‹ ===")
    
    try:
        tracker = CostTracker()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = tracker.generate_report()
        print(report)
        
        # å¯¼å‡ºæ•°æ®
        tracker.export_data("usage_report.json")
        
    except Exception as e:
        print(f"Error: {e}")


def example_custom_configuration():
    """ç¤ºä¾‹: è‡ªå®šä¹‰é…ç½®"""
    print("\n=== è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹ ===")
    
    try:
        monitor = BillingMonitor()
        
        # æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹
        custom_models = [
            ModelConfig(
                name="claude-3-opus",
                input_token_price=0.015,
                output_token_price=0.075,
                max_tokens=200000
            ),
            ModelConfig(
                name="gemini-pro",
                input_token_price=0.0005,
                output_token_price=0.0015,
                max_tokens=32768
            )
        ]
        
        for model in custom_models:
            monitor.config_manager.add_model_config(model)
            print(f"âœ… æ·»åŠ æ¨¡å‹é…ç½®: {model.name}")
        
        # è®¾ç½®ä¸¥æ ¼çš„é™åˆ¶
        strict_thresholds = ThresholdConfig(
            daily_cost_limit=1.0,        # æ¯æ—¥$1é™åˆ¶
            monthly_cost_limit=20.0,     # æ¯æœˆ$20é™åˆ¶
            daily_token_limit=100000,    # æ¯æ—¥10ä¸‡tokené™åˆ¶
            warning_threshold=0.7        # 70%è­¦å‘Š
        )
        
        monitor.config_manager.update_thresholds(strict_thresholds)
        print("âœ… æ›´æ–°é˜ˆå€¼é…ç½®")
        
        # æ˜¾ç¤ºå½“å‰é…ç½®
        config = monitor.config
        print(f"\nğŸ“‹ å½“å‰é…ç½®:")
        print(f"   æ¨¡å‹æ•°é‡: {len(config.models)}")
        print(f"   æ—¥æˆæœ¬é™åˆ¶: ${config.thresholds.daily_cost_limit}")
        print(f"   æœˆæˆæœ¬é™åˆ¶: ${config.thresholds.monthly_cost_limit}")
        print(f"   è­¦å‘Šé˜ˆå€¼: {config.thresholds.warning_threshold*100}%")
        
    except Exception as e:
        print(f"Error: {e}")


def main():
    """è¿è¡Œé«˜çº§ç¤ºä¾‹"""
    print("OpenAI Billing Monitor - é«˜çº§ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    # è¿è¡Œä¸éœ€è¦APIè°ƒç”¨çš„ç¤ºä¾‹
    example_model_comparison()
    example_cost_tracking()
    example_custom_configuration()
    
    print("\n" + "=" * 60)
    print("é«˜çº§ç¤ºä¾‹å®Œæˆ!")
    print("\nå–æ¶ˆæ³¨é‡Šå…¶ä»–ç¤ºä¾‹æ¥æµ‹è¯•APIè°ƒç”¨åŠŸèƒ½")
    print("ï¼ˆæ³¨æ„ï¼šè¿™å°†äº§ç”Ÿå®é™…çš„APIè´¹ç”¨ï¼‰")
    
    # å¦‚æœæƒ³æµ‹è¯•å®é™…çš„APIè°ƒç”¨ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Šï¼š
    # example_chatbot()
    # example_batch_processing()


if __name__ == "__main__":
    main()
